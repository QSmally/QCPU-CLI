
// Semantic Analysed Intermediate Representation

const std = @import("std");
const AsmAst = @import("AsmAst.zig");
const Error = @import("Error.zig");
const Source = @import("Source.zig");
const Token = @import("Token.zig");

const AsmSemanticAir = @This();

pub const Instruction = union(enum) {
    ast: struct { u3 },

    mst: struct { u1, u2, u16 },
    mst_: struct { u1, u2, u16 }, // _ = addressable, relative to section or barrier

    // adds fixed zero bytes
    ld_padding: struct { usize },

    pub fn size(self: Instruction) usize {
        return switch (self) {
            .ast => 1,
            .mst,
            .mst_ => 3,
            .ld_padding => |args| args[0]
        };
    }
};

pub const SymbolFile = struct {
    path: []const u8,
    namespace: ?[]const u8,
    sema_unit: ?*const AsmSemanticAir = null
};

pub const Symbol = union(enum) {

    pub const Locatable = struct {
        token: Token,
        symbol: Symbol
    };

    label: Label,
    define: Define,
    header: Header,

    pub const Label = struct {
        instr_node: AsmAst.Index,
        is_public: bool
    };

    pub const Define = struct {
        value_node: AsmAst.Index,
        is_public: bool
    };

    pub const Header = struct {
        arguments: AsmAst.IndexRange,
        content: AsmAst.IndexRange,
        is_public: bool
    };
};

pub const Section = struct {

    /// Grows with the use of @align to ensure the correct padding is calculated
    /// ahead-of-time.
    alignment: usize = 0,
    /// A boolean to indicate whether this section is allowed to be removed by
    /// unreachable-code-elimination.
    is_removable: bool = true,
    /// Opaque list of (pseudo)instructions. All addresses during assembletime
    /// are relative to the start of the section.
    content: InstructionList = .empty,
    /// A section is allowed to be split by @barrier or duplicate @section
    /// tags, which links to a new, unnamed section.
    next: ?*Section = null,

    pub fn append(self: *Section, new_section: *Section) void {
        if (self.next) |next_section|
            return next_section.append(new_section);
        self.next = new_section;
    }
};

const FileList = std.ArrayListUnmanaged(SymbolFile);
const SymbolMap = std.StringArrayHashMapUnmanaged(Symbol.Locatable);
const SectionMap = std.StringArrayHashMapUnmanaged(*Section);
const InstructionList = std.ArrayListUnmanaged(Instruction);
const ErrorList = std.ArrayListUnmanaged(Error);
const SemanticAirMap = std.StringArrayHashMapUnmanaged(*AsmSemanticAir);

allocator: std.mem.Allocator,
source: Source,
nodes: []const AsmAst.Node,
/// May not be modified during semantic analysis.
/// fixme: force namespaces to remove cross duplication problem?
imports: FileList,
/// Any symbol in the current unit. May not be modified during semantic
/// analysis.
symbols: SymbolMap,
sections: SectionMap,
current_section: ?*Section,
errors: ErrorList,

pub fn init(allocator: std.mem.Allocator, source: Source, nodes: []const AsmAst.Node) !AsmSemanticAir {
    var self = AsmSemanticAir {
        .allocator = allocator,
        .source = source,
        .nodes = nodes,
        .imports = .empty,
        .symbols = .empty,
        .sections = .empty,
        .current_section = null,
        .errors = .empty };
    errdefer self.deinit();

    astgen_assert(nodes.len > 0);
    astgen_assert(nodes[0].tag == .container);
    try self.prepare_opaque_container(nodes[0]);
    return self;
}

fn destroy_section(self: *AsmSemanticAir, section: *Section) void {
    if (section.next) |next|
        self.destroy_section(next);
    section.content.deinit(self.allocator);
    self.allocator.destroy(section);
}

pub fn deinit(self: *AsmSemanticAir) void {
    self.imports.deinit(self.allocator);
    self.symbols.deinit(self.allocator);

    for (self.sections.values()) |section|
        self.destroy_section(section);
    self.sections.deinit(self.allocator);
    self.current_section = null;

    for (self.errors.items) |err|
        self.allocator.free(err.message);
    self.errors.deinit(self.allocator);
}

/// SemanticAir will assume certain state generated by AstGen, and asserts them
/// for debugging purposes. If an assumption is not met, SemanticAir will
/// panic.
fn astgen_assert(ok: bool) void {
    if (!ok) unreachable;
}

fn astgen_failure() noreturn {
    unreachable;
}

/// To calculate alignment.
fn find_available_mask(from_address: usize, mask: usize) usize {
    for (from_address..std.math.maxInt(usize)) |address|
        if (address % mask == 0)
            return address;
    unreachable;
}

/// Instructions are variably sized, which requires the size of a section to be
/// calculated iteratively.
fn find_section_size(section: *Section) usize {
    var address: usize = 0;
    for (section.content.items) |instruction|
        address += instruction.size();
    return address;
}

fn node_is_null_or(self: *AsmSemanticAir, index: AsmAst.Index, tag: AsmAst.Node.Tag) bool {
    return index == AsmAst.Null or self.nodes[index].tag == tag;
}

fn node_is(self: *AsmSemanticAir, index: AsmAst.Index, tag: AsmAst.Node.Tag) bool {
    return index != AsmAst.Null and self.nodes[index].tag == tag;
}

fn node_len(self: *AsmSemanticAir, index: AsmAst.Index) ?u32 {
    if (!node_is(index, .container))
        return null;
    const node = self.nodes[index];
    return node.operands.rhs - node.operands.lhs;
}

fn not_null(self: *AsmSemanticAir, index: AsmAst.Index) bool {
    _ = self;
    return index != AsmAst.Null;
}

fn is_null(self: *AsmSemanticAir, index: AsmAst.Index) bool {
    _ = self;
    return index == AsmAst.Null;
}

fn node_unwrap(self: *AsmSemanticAir, index: AsmAst.Index) ?AsmAst.Node {
    return if (self.not_null(index)) self.nodes[index] else null;
}

const ContainerIterator = struct {

    sema: *AsmSemanticAir,
    cursor: AsmAst.Index,
    start: AsmAst.Index,
    end: AsmAst.Index,
    context_token: ?Token = null,

    pub fn init(sema: *AsmSemanticAir, node: AsmAst.Node) ContainerIterator {
        return .{
            .sema = sema,
            .cursor = 0,
            .start = node.operands.lhs,
            .end = node.operands.rhs };
    }

    pub fn init_index(sema: *AsmSemanticAir, index: AsmAst.Index) ContainerIterator {
        if (index == AsmAst.Null)
            return .{ .sema = sema, .cursor = 0, .start = 0, .end = 0 };
        const node = sema.nodes[index];
        return ContainerIterator.init(sema, node);
    }

    pub fn init_index_context(sema: *AsmSemanticAir, index: AsmAst.Index, context_token: Token) ContainerIterator {
        var iterator = ContainerIterator.init_index(sema, index);
        iterator.context_token = context_token;
        return iterator;
    }

    pub fn expect_empty(sema: *AsmSemanticAir, index: AsmAst.Index, context_token: Token) !void {
        var iterator = ContainerIterator.init_index_context(sema, index, context_token);
        try iterator.expect_end();
    }

    fn is_the_end(self: *ContainerIterator) bool {
        return self.current() == self.end or self.start == self.end;
    }

    fn current(self: *ContainerIterator) AsmAst.Index {
        return self.start + self.cursor;
    }

    fn current_token(self: *ContainerIterator) Token {
        const node = self.sema.nodes[self.current()];
        return self.sema.source.tokens[node.token];
    }

    pub fn next(self: *ContainerIterator) ?AsmAst.Node {
        if (self.is_the_end())
            return null;
        const index = self.current();
        self.cursor += 1;
        return self.sema.nodes[index];
    }

    pub fn expect(self: *ContainerIterator, tag: AsmAst.Node.Tag) !?AsmAst.Node {
        if (self.is_the_end()) {
            if (self.context_token) |context_token_|
                try self.sema.add_error(error.ExpectedContext, .{ tag, context_token_ }) else
                try self.sema.add_error(error.ExpectedEmpty, tag);
            return null;
        } else if (self.sema.nodes[self.current()].tag != tag) {
            try self.sema.add_error(error.Expected, .{ tag, self.current_token() });
            return null;
        }
        return self.next();
    }

    pub fn gracefully_expect(self: *ContainerIterator, tag: AsmAst.Node.Tag) !?AsmAst.Node {
        if (self.is_the_end())
            return null;
        if (self.sema.nodes[self.current()].tag != tag) {
            try self.sema.add_error(error.Expected, .{ tag, self.current_token() });
            return null;
        }
        return self.next();
    }

    pub fn expect_any(self: *ContainerIterator) !?AsmAst.Index {
        if (self.is_the_end()) {
            const str = Token.string("an argument");
            if (self.context_token) |context_token_|
                try self.sema.add_error(error.ExpectedContext, .{ str, context_token_ }) else
                try self.sema.add_error(error.ExpectedEmpty, str);
            return null;
        }

        _ =  self.next();
        return self.current();
    }

    pub fn expect_end(self: *ContainerIterator) !void {
        if (!self.is_the_end())
            try self.sema.add_error(error.Unexpected, self.current_token());
    }
};

const SemanticError = error {
    Expected,
    ExpectedContext,
    ExpectedEmpty,
    Unexpected,
    UnsupportedOption,
    UselessSentinel,
    DuplicateSymbol,
    AlignPowerTwo,
    RegionExceedsSize,
    NoteDefinedHere,
    Generic
};

fn add_error(self: *AsmSemanticAir, comptime err: SemanticError, argument: anytype) !void {
    @branchHint(.unlikely);

    const message = switch (err) {
        error.Expected => "expected {s}, found {s}",
        error.ExpectedContext => "expected {s} in {s}",
        error.ExpectedEmpty => "expected {s}",
        error.Unexpected => "unexpectedly got {s}",
        error.UnsupportedOption => "unsupported option: {s}",
        error.UselessSentinel => "useless sentinel",
        error.DuplicateSymbol => "duplicate symbol '{s}'",
        error.AlignPowerTwo => "alignment of {} is not a power of two",
        error.RegionExceedsSize => "region of opaque size {} exceeds fixed region of {} bytes",
        error.NoteDefinedHere => "{s} defined here",
        error.Generic => "{s}: {s}"
    };

    const is_note = switch (err) {
        error.NoteDefinedHere => true,
        else => false
    };

    const token: ?Token = switch (err) {
        error.Expected,
        error.ExpectedContext,
        error.DuplicateSymbol,
        error.AlignPowerTwo,
        error.NoteDefinedHere => argument[1],
        error.Unexpected,
        error.UnsupportedOption,
        error.UselessSentinel => argument,
        error.RegionExceedsSize => argument[2],
        else => null
    };
    const token_location = if (token) |token_|
        self.source.location_of(token_.location) else
        null;
    const token_slice = if (token) |token_|
        token_.location.slice(self.source.buffer) else
        null;
    const arguments = switch (err) {
        error.Expected,
        error.ExpectedContext => .{ argument[0].fmt(), argument[1].tag.fmt() },
        error.ExpectedEmpty => .{ argument.fmt() },
        error.Unexpected => .{ argument.tag.fmt() },
        error.UnsupportedOption => .{ token_slice.? },
        error.UselessSentinel => .{},
        error.DuplicateSymbol,
        error.AlignPowerTwo => .{ argument[0] },
        error.RegionExceedsSize => .{ argument[0], argument[1] },
        error.NoteDefinedHere => .{ argument[0].fmt() },
        else => argument
    };

    const format = try std.fmt.allocPrint(self.allocator, message, arguments);

    try self.errors.append(self.allocator, .{
        .id = err,
        .token = token,
        .is_note = is_note,
        .message = format,
        .location = token_location });
}

fn prepare_opaque_container(self: *AsmSemanticAir, parent_node: AsmAst.Node) !void {
    for (parent_node.operands.lhs..parent_node.operands.rhs) |node_idx| {
        const node = self.nodes[node_idx];
        const token = self.source.tokens[node.token];

        switch (node.tag) {
            .builtin => {
                astgen_assert(self.node_is_null_or(node.operands.lhs, .container));
                astgen_assert(self.node_is(node.operands.rhs, .composite));
                const composite = self.nodes[node.operands.rhs];
                astgen_assert(self.node_is_null_or(composite.operands.lhs, .container));
                astgen_assert(self.node_is_null_or(composite.operands.rhs, .container));

                builtin_checklist: switch (token.tag) {
                    .builtin_define => {
                        const define = try self.prepare_define(node) orelse continue;
                        try define.maybe_emit_duplicate_error(self);
                        try self.symbols.put(self.allocator, define.name, .{
                            .token = define.token,
                            .symbol = define.symbol });
                    },
                    .builtin_header => {
                        const header = try self.prepare_header(node) orelse continue;
                        try header.maybe_emit_duplicate_error(self);
                        try self.symbols.put(self.allocator, header.name, .{
                            .token = header.token,
                            .symbol = header.symbol });
                        continue :builtin_checklist .builtin_section;
                    },
                    .builtin_symbols => {
                        const symbols = try self.prepare_symbols(node) orelse continue;
                        // fixme: check for duplicate namespaces?
                        try self.imports.append(self.allocator, symbols);
                    },

                    .builtin_region,
                    .builtin_section => {
                        // fixme: empty regions will throw an error
                        // fixme: empty sections aren't a Null opaque
                        astgen_assert(self.node_is(composite.operands.rhs, .container));
                        // if (self.is_null(composite.operands.rhs))
                        //     return;
                        const opaque_ = self.nodes[composite.operands.rhs];
                        try self.prepare_opaque_container(opaque_);
                    },

                    // nothing to do here
                    .builtin_align,
                    .builtin_barrier => {},

                    // transparent in the AST
                    .builtin_end => astgen_failure(),

                    // non-builtin tokens shouldn't be in node tags
                    else => astgen_failure()
                }
            },

            .instruction => {
                astgen_assert(self.node_is_null_or(node.operands.lhs, .container));
                astgen_assert(self.node_is_null_or(node.operands.rhs, .composite));

                if (self.is_null(node.operands.rhs))
                    continue;
                const composite = self.nodes[node.operands.rhs];
                astgen_assert(self.node_is_null_or(composite.operands.lhs, .container));
                astgen_assert(self.node_is_null_or(composite.operands.rhs, .modifier));

                if (self.is_null(composite.operands.lhs))
                    continue;
                var labels = ContainerIterator.init_index(self, composite.operands.lhs);

                while (try labels.gracefully_expect(.label)) |label_node| {
                    astgen_assert(self.is_null(label_node.operands.lhs));
                    astgen_assert(self.is_null(label_node.operands.rhs));

                    const label = try self.prepare_label(label_node, @intCast(node_idx)) orelse continue;
                    try label.maybe_emit_duplicate_error(self);
                    try self.symbols.put(self.allocator, label.name, .{
                        .token = label.token,
                        .symbol = label.symbol });
                }
            },

            else => astgen_failure()
        }
    }
}

const NamedSymbol = struct {

    name: []const u8,
    token: Token,
    symbol: Symbol,

    pub fn maybe_emit_duplicate_error(self: *const NamedSymbol, sema: *AsmSemanticAir) !void {
        if (sema.symbols.get(self.name)) |existing_symbol| {
            try sema.add_error(error.DuplicateSymbol, .{ self.name, self.token });
            try sema.add_error(error.NoteDefinedHere, .{ Token.string("previously"), existing_symbol.token });
        }
    }
};

fn prepare_define(self: *AsmSemanticAir, node: AsmAst.Node) !?NamedSymbol {
    const composite = self.nodes[node.operands.rhs];
    const options_ = if (self.node_unwrap(composite.operands.lhs)) |options_|
        try self.parse_options(options_, &.{ .expose }) else
        null;
    defer self.free_options(options_);
    const define_token = self.source.tokens[node.token];
    var arguments = ContainerIterator.init_index_context(self, node.operands.lhs, define_token);

    const name_node = try arguments.expect(.identifier) orelse return null;
    const name_token = self.source.tokens[name_node.token];
    const name = name_token.location.slice(self.source.buffer);

    const value_node = try arguments.expect_any() orelse return null;
    try arguments.expect_end();
    astgen_assert(self.is_null(composite.operands.rhs));

    const define = Symbol.Define {
        .value_node = value_node,
        .is_public = self.contains_option(options_, .expose) };
    return .{
        .name = name,
        .token = define_token,
        .symbol = .{ .define = define } };
}

fn prepare_header(self: *AsmSemanticAir, node: AsmAst.Node) !?NamedSymbol {
    const composite = self.nodes[node.operands.rhs];
    const options_ = if (self.node_unwrap(composite.operands.lhs)) |options_|
        try self.parse_options(options_, &.{ .expose }) else
        null;
    defer self.free_options(options_);
    const header_token = self.source.tokens[node.token];
    var arguments = ContainerIterator.init_index_context(self, node.operands.lhs, header_token);

    const name_node = try arguments.expect(.identifier) orelse return null;
    const name_token = self.source.tokens[name_node.token];
    const name = name_token.location.slice(self.source.buffer);

    while (try arguments.gracefully_expect(.identifier) != null) {}
    astgen_assert(self.node_is_null_or(composite.operands.rhs, .container));

    const header = Symbol.Header {
        .arguments = .{
            .lhs = arguments.start + 1, // skip name
            .rhs = arguments.end },
        .content = if (self.not_null(composite.operands.rhs))
            self.nodes[composite.operands.rhs].operands else
            .{},
        .is_public = self.contains_option(options_, .expose) };
    return .{
        .name = name,
        .token = header_token,
        .symbol = .{ .header = header } };
}

fn prepare_symbols(self: *AsmSemanticAir, node: AsmAst.Node) !?SymbolFile {
    const composite = self.nodes[node.operands.rhs];
    if (self.node_unwrap(composite.operands.lhs)) |options_|
        _ = try self.parse_options(options_, &.{});
    const symbols_token = self.source.tokens[node.token];
    var arguments = ContainerIterator.init_index_context(self, node.operands.lhs, symbols_token);

    const path_string_node = try arguments.expect(.string) orelse return null;
    const path_string_token = self.source.tokens[path_string_node.token];
    const path_string = path_string_token.content_slice(self.source.buffer);
    astgen_assert(self.node_is_null_or(path_string_node.operands.lhs, .integer));
    astgen_assert(path_string_token.tag == .string_literal);

    if (path_string_node.operands.lhs != AsmAst.Null) {
        const sentinel_node = self.nodes[path_string_node.operands.lhs];
        const sentinel_token = self.source.tokens[sentinel_node.token];
        try self.add_error(error.UselessSentinel, sentinel_token);
    }

    const namespace_node = try arguments.gracefully_expect(.identifier);
    const namespace = if (namespace_node) |namespace_node_|
        self.source.tokens[namespace_node_.token].location.slice(self.source.buffer) else
        null;
    try arguments.expect_end();
    astgen_assert(self.is_null(composite.operands.rhs));

    return .{
        .path = path_string,
        .namespace = namespace };
}

const Option = enum {
    expose,
    noelimination
};

const options_map = std.StaticStringMap(Option).initComptime(.{
    .{ "expose", .expose },
    .{ "noelimination", .noelimination }
});

/// If the allow list is empty, it's guaranteed that there's no need to call
/// free on the returned slice.
fn parse_options(self: *AsmSemanticAir, node: AsmAst.Node, allow_list: []const Option) ![]const Option {
    astgen_assert(node.tag == .container);
    const len = node.operands.rhs - node.operands.lhs;

    var options_ = try std
        .ArrayList(Option)
        .initCapacity(self.allocator, @min(len, allow_list.len));
    errdefer options_.deinit();

    for (node.operands.lhs..node.operands.rhs) |index| {
        astgen_assert(self.node_is(@intCast(index), .option));
        const option_node = self.nodes[index];
        astgen_assert(self.not_null(option_node.token));
        const option_token = self.source.tokens[option_node.token];
        astgen_assert(option_token.tag == .option);

        const option_string = option_token.location.slice(self.source.buffer);
        const option = options_map.get(option_string) orelse astgen_failure();

        if (std.mem.indexOfScalar(Option, allow_list, option) == null)
            try self.add_error(error.UnsupportedOption, option_token) else
            try options_.append(option);
    }

    if (allow_list.len == 0) {
        std.debug.assert(options_.items.len == 0);
        options_.deinit();
        return &.{};
    }

    return try options_.toOwnedSlice();
}

fn contains_option(self: *AsmSemanticAir, options_: ?[]const Option, option: Option) bool {
    _ = self;
    return if (options_) |options__|
        std.mem.indexOfScalar(Option, options__, option) != null else
        false;
}

fn free_options(self: *AsmSemanticAir, options_: ?[]const Option) void {
    if (options_) |options__|
        self.allocator.free(options__);
}

fn prepare_label(self: *AsmSemanticAir, node: AsmAst.Node, instr_index: AsmAst.Index) !?NamedSymbol {
    const label_token = self.source.tokens[node.token];
    astgen_assert(label_token.tag == .label or label_token.tag == .private_label);

    const is_public = label_token.tag == .label;
    const label_name = label_token.content_slice(self.source.buffer);
    astgen_assert(self.is_null(node.operands.rhs));

    const label = Symbol.Label {
        .instr_node = instr_index,
        .is_public = is_public };
    return .{
        .name = label_name,
        .token = label_token,
        .symbol = .{ .label = label } };
}

pub fn resolve_imports(self: *AsmSemanticAir, units: *const SemanticAirMap, this_path: []const u8) !void {
    for (self.imports.items) |*import| {
        // fixme: add filesystem (and test) interface support for matching
        // filenames/file identifiers
        if (std.mem.eql(u8, import.path, this_path)) {
            try self.add_error(error.Generic, .{ "cannot import itself", import.path });
            continue;
        }

        import.sema_unit = units.get(import.path) orelse {
            try self.add_error(error.Generic, .{ "missing sema unit", import.path });
            continue;
        };
    }
}

/// May only be called once, and subsequent calls are considered undefined
/// behaviour.
pub fn semantic_analyse(self: *AsmSemanticAir) !void {
    try self.analyse_container(self.nodes[0]);
}

fn analyse_container(self: *AsmSemanticAir, parent_node: AsmAst.Node) !void {
    for (parent_node.operands.lhs..parent_node.operands.rhs) |node_idx| {
        const node = self.nodes[node_idx];
        const token = self.source.tokens[node.token];

        switch (node.tag) {
            .builtin => switch (token.tag) {
                .builtin_align => try self.emit_align(node),
                .builtin_barrier => try self.emit_barrier(node),

                .builtin_region => {
                    const section = self.current_section orelse astgen_failure();
                    const begin_address = find_section_size(section);
                    const composite = self.nodes[node.operands.rhs];
                    const opaque_ = self.nodes[composite.operands.rhs];
                    try self.analyse_container(opaque_);

                    const len = find_section_size(section) - begin_address;
                    try self.emit_region(node, len);
                },

                .builtin_section => {
                    self.emit_section(node) catch |err| switch (err) {
                        error.SectionCreateFailed => continue,
                        else => |err_| return err_
                    };

                    const composite = self.nodes[node.operands.rhs];
                    const opaque_ = self.nodes[composite.operands.rhs];
                    try self.analyse_container(opaque_);
                },

                // nothing to do here
                .builtin_define,
                .builtin_header,
                .builtin_symbols => {},

                // transparent in the AST
                .builtin_end => astgen_failure(),

                // non-builtin tokens shouldn't be in the node tags
                else => astgen_failure()
            },

            .instruction => {},

            else => astgen_failure()
        }
    }
}

fn emit_align(self: *AsmSemanticAir, node: AsmAst.Node) !void {
    const composite = self.nodes[node.operands.rhs];
    if (self.node_unwrap(composite.operands.lhs)) |options_|
        _ = try self.parse_options(options_, &.{});
    const align_token = self.source.tokens[node.token];
    var arguments = ContainerIterator.init_index_context(self, node.operands.lhs, align_token);

    const alignment_node = try arguments.expect(.integer) orelse return;
    const alignment_token = self.source.tokens[alignment_node.token];
    const alignment = alignment_token.location.slice(self.source.buffer);
    try arguments.expect_end();

    const alignment_ = std.fmt.parseInt(usize, alignment, 0) catch astgen_failure();
    if (!std.math.isPowerOfTwo(alignment_))
        return try self.add_error(error.AlignPowerTwo, .{ alignment_, align_token });
    const section = self.current_section orelse astgen_failure();
    const current_address = find_section_size(section);
    const padding = find_available_mask(current_address, alignment_) - current_address;

    try section.content.append(self.allocator, .{ .ld_padding = .{ padding } });
    section.alignment = @max(section.alignment, alignment_);
}

fn emit_barrier(self: *AsmSemanticAir, node: AsmAst.Node) !void {
    const composite = self.nodes[node.operands.rhs];
    if (self.node_unwrap(composite.operands.lhs)) |options_|
        _ = try self.parse_options(options_, &.{});
    const barrier_token = self.source.tokens[node.token];
    try ContainerIterator.expect_empty(self, node.operands.lhs, barrier_token);

    const existing_section = self.current_section orelse return astgen_failure();
    const section = try self.allocator.create(Section);
    section.* = .{};

    existing_section.append(section);
    self.current_section = section;
}

fn emit_region(self: *AsmSemanticAir, node: AsmAst.Node, opaque_len: usize) !void {
    const composite = self.nodes[node.operands.rhs];
    if (self.node_unwrap(composite.operands.lhs)) |options_|
        _ = try self.parse_options(options_, &.{});
    const region_token = self.source.tokens[node.token];
    var arguments = ContainerIterator.init_index_context(self, node.operands.lhs, region_token);

    const size_node = try arguments.expect(.integer) orelse return;
    const size_token = self.source.tokens[size_node.token];
    const size = size_token.location.slice(self.source.buffer);
    try arguments.expect_end();

    const size_ = std.fmt.parseInt(usize, size, 0) catch astgen_failure();
    if (opaque_len > size_)
        return try self.add_error(error.RegionExceedsSize, .{ opaque_len, size_, region_token });
    const section = self.current_section orelse return astgen_failure();
    const padding = size_ - opaque_len;
    try section.content.append(self.allocator, .{ .ld_padding = .{ padding } });
}

fn emit_section(self: *AsmSemanticAir, node: AsmAst.Node) !void {
    const composite = self.nodes[node.operands.rhs];
    const options_ = if (self.node_unwrap(composite.operands.lhs)) |options_|
        try self.parse_options(options_, &.{ .noelimination }) else
        null;
    defer self.free_options(options_);
    const section_token = self.source.tokens[node.token];
    var arguments = ContainerIterator.init_index_context(self, node.operands.lhs, section_token);

    const name_node = try arguments.expect(.identifier) orelse return error.SectionCreateFailed;
    const name_token = self.source.tokens[name_node.token];
    const name = name_token.location.slice(self.source.buffer);
    try arguments.expect_end();

    const section = try self.allocator.create(Section);
    section.* = .{};

    if (self.sections.get(name)) |existing_section|
        existing_section.append(section) else
        try self.sections.put(self.allocator, name, section);
    self.current_section = section;
}

pub fn evaluate_symbol(comptime T: type, self: *AsmSemanticAir) !T {
    _ = self;
}

// Tests

const options = @import("options");
const Tokeniser = @import("AsmTokeniser.zig");

const stderr = std.io
    .getStdErr()
    .writer();

fn testSema(input: [:0]const u8) !struct { AsmAst, AsmSemanticAir } {
    var tokeniser = Tokeniser.init(input);
    const source = try Source.init(std.testing.allocator, &tokeniser);
    errdefer source.deinit();
    var ast = try AsmAst.init(std.testing.allocator, source);
    errdefer ast.deinit();

    for (ast.errors) |err|
        try err.write("test.s", input, stderr);
    try std.testing.expect(ast.errors.len == 0);

    return .{ ast, try AsmSemanticAir.init(std.testing.allocator, source, ast.nodes) };
}

fn testSemaFree(ast: *AsmAst, sema: *AsmSemanticAir) void {
    ast.deinit();
    sema.deinit();
    sema.source.deinit();
}

fn testSema1(input: [:0]const u8) !void {
    var ast, var sema = try testSema(input);
    defer testSemaFree(&ast, &sema);

    if (options.dump) {
        try stderr.print("Imports ({}):\n", .{ sema.imports.items.len });
        for (sema.imports.items) |import|
            try stderr.print("    {s} = {s}\n", .{ import.namespace orelse "_", import.path });
        try stderr.print("Symbols ({}):\n", .{ sema.symbols.count() });
        for (sema.symbols.keys()) |symbol_name| {
            const symbol = sema.symbols.get(symbol_name) orelse unreachable;
            switch (symbol.symbol) {
                .label => |label| try stderr.print("    {s} = instr:{} public:{}\n", .{
                    symbol_name,
                    label.instr_node,
                    label.is_public }),
                .define => |define| try stderr.print("    {s} = root:{} public:{}\n", .{
                    symbol_name,
                    define.value_node,
                    define.is_public }),
                .header => |header| try stderr.print("    {s} = args:{}..{} nodes:{}..{} public:{}\n", .{
                    symbol_name,
                    header.arguments.lhs,
                    header.arguments.rhs,
                    header.content.lhs,
                    header.content.rhs,
                    header.is_public })
            }
        }
    }

    for (sema.errors.items) |err|
        try err.write("test.s", input, stderr);
    try std.testing.expect(sema.errors.items.len == 0);
}

fn testSema2(input: [:0]const u8) !void {
    var ast, var sema = try testSema(input);
    defer testSemaFree(&ast, &sema);

    try sema.semantic_analyse();

    if (options.dump) {
        for (sema.sections.keys()) |section_name| {
            const section = sema.sections.get(section_name) orelse unreachable;
            var dumping_section: ?*Section = section;
            try stderr.print("@section {s} (align {})\n", .{ section_name, section.alignment });

            while (dumping_section) |dumping_section_| {
                for (dumping_section_.content.items) |instr| {
                    switch (instr) {
                        inline else => |instr_| try stderr.print("    {s}({}) : {}\n", .{ @tagName(instr), instr.size(), instr_ })
                    }
                }

                if (dumping_section_.next) |next_dumping_section|
                    try stderr.print("@barrier (align {})\n", .{ next_dumping_section.alignment });
                dumping_section = dumping_section_.next;
            }
        }
    }

    for (sema.errors.items) |err|
        try err.write("test.s", input, stderr);
    try std.testing.expect(sema.errors.items.len == 0);
}

fn testSema3(input_0: [:0]const u8, input_1: [:0]const u8) !void {
    var sema_map = SemanticAirMap.empty;
    defer sema_map.deinit(std.testing.allocator);

    var ast_0, var sema_0 = try testSema(input_0);
    defer testSemaFree(&ast_0, &sema_0);
    try sema_map.put(std.testing.allocator, "test_0.s", &sema_0);

    var ast_1, var sema_1 = try testSema(input_1);
    defer testSemaFree(&ast_1, &sema_1);
    try sema_map.put(std.testing.allocator, "test_1.s", &sema_1);

    for (sema_map.values()) |per_sema|
        try per_sema.resolve_imports(&sema_map, "foo");
    for (sema_map.values()) |per_sema|
        try per_sema.semantic_analyse();

    for (sema_0.errors.items) |err|
        try err.write("test_0.s", input_0, stderr);
    for (sema_1.errors.items) |err|
        try err.write("test_1.s", input_1, stderr);
    try std.testing.expect(sema_0.errors.items.len == 0);
    try std.testing.expect(sema_1.errors.items.len == 0);
}

test "full fledge" {
    try testSema1(
        \\@symbols "foo", foo
        \\@symbols "bar"
        \\@define(expose) foo, bar
        \\@header bar
        \\          ast
        \\@end
        \\@section foo
        \\          ast
        \\.aaa:     ast
        \\bbb:      ast
        \\@define awd, awd
    );

    try testSema2(
        \\@define foo, bar
        \\@define bar, 5
        \\@section(noelimination) foo
        \\              @align 8
        \\              @align 16
        \\          @region 24
        \\              ast
        \\          @end
        \\              @align 16
        \\@barrier
        \\              @align 4
    );

    try testSema3(
        \\@symbols "test_0.s"
    ,
        \\@symbols "test_1.s"
    );
}
